{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Discriminative Analysis\n",
    "### Generative Learning Algorithm vs Discriminitive Learning Algorithm\n",
    "Alogirthm that tries to learn mappings from input space $ \\mathcal{x} $ to the output labels $ \\mathcal{y} $ ( such as logistic regression, linear regression etc.) are called **Discriminitive Learning Algorithm(DLA)**. In other wards discriminitive learning algorithm tries to learn $ y $ given $ x $. Mathemetically $ P(y | x) $. On the other hand, algorithm that tries to learn $ x $ given $ y $ $ (i. e. p(x | y)) $ is called **Generative Learning Algorithm (GLA)**. Naive Bayes, Gaussian discriminant analysis are the example of GLA. While DLA tries to find a dicision boundry based on the input data, GLA tries to fit a gaussian in each input feature. \n",
    "![DLA vs GLA](img/GLA_DLA.png)\n",
    "You can learn more about the differences [here](https://medium.com/@mlengineer/generative-and-discriminative-models-af5637a66a3#:~:text=In%20General%2C%20A%20Discriminative%20model,actual%20distribution%20of%20each%20class.&text=A%20Generative%20Model%20%E2%80%8Clearns%20the,the%20help%20of%20Bayes%20Theorem.). \n",
    "\n",
    "### Multivariate Gaussian Distribution\n",
    "Gaussian Discriminant Analysis model assumes that $ p(x | y) $ is distributed according to a multivariate normal distribution, which is parameterized by a **mean vector** $ \\mu \\in \\mathbb{R}^n $ and a **covariance matrix** $ \\Sigma \\in \\mathbb{R}^{nxn} $. This can also be written as $ \\mathcal{N}(\\mu, \\Sigma) $ and it's density function can be given by:\n",
    "$$ \n",
    "p(x;\\mu,\\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}exp\\Bigg(-\\frac{1}{2}\\big(x - \\mu\\big)^T\\Sigma^{-1}\\big(x - \\mu\\big)\\Bigg)\n",
    "$$\n",
    "The mean vector and covariance matrix will determine the shape of the probability density function. In the following section you can play with these parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdbc293e4774386be42930a065a96c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='mu1', max=3.0, min=-3.0), FloatSlider(value=0.0, desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(mu1=(-3,3,0.1),  mu2=(-3,3.0,0.1), diagonal_1=(0,3.0,0.1), diagonal_2=(0,3.0,0.1), non_diagonal=(-3,3.0,0.1))\n",
    "def visualize_multivariate_gaussian(mu1=0.0, mu2=0.0, diagonal_1=1, diagonal_2=1, non_diagonal=.5):\n",
    "    # This code snippet is taken from here [https://scipython.com/blog/visualizing-the-bivariate-gaussian-distribution/]\n",
    "    N = 300\n",
    "    X = np.linspace(-3, 3, N)\n",
    "    Y = np.linspace(-3, 4, N)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "    # Mean vector and covariance matrix\n",
    "    mu = np.array([mu1, mu2])\n",
    "    Sigma = np.array([[ diagonal_1 , non_diagonal], [non_diagonal,  diagonal_2]])\n",
    "\n",
    "    # Pack X and Y into a single 3-dimensional array\n",
    "    pos = np.empty(X.shape + (2,))\n",
    "    pos[:, :, 0] = X\n",
    "    pos[:, :, 1] = Y\n",
    "\n",
    "    def multivariate_gaussian(pos, mu, Sigma):\n",
    "        \"\"\"Return the multivariate Gaussian distribution on array pos.\n",
    "\n",
    "        pos is an array constructed by packing the meshed arrays of variables\n",
    "        x_1, x_2, x_3, ..., x_k into its _last_ dimension.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n = mu.shape[0]\n",
    "        Sigma_det = np.linalg.det(Sigma)\n",
    "        Sigma_inv = np.linalg.inv(Sigma)\n",
    "        N = np.sqrt((2*np.pi)**n * Sigma_det)\n",
    "        # This einsum call calculates (x-mu)T.Sigma-1.(x-mu) in a vectorized\n",
    "        # way across all the input variables.\n",
    "        fac = np.einsum('...k,kl,...l->...', pos-mu, Sigma_inv, pos-mu)\n",
    "\n",
    "        return np.exp(-fac / 2) / N\n",
    "\n",
    "    # The distribution on the variables X, Y packed into pos.\n",
    "    Z = multivariate_gaussian(pos, mu, Sigma)\n",
    "\n",
    "    # Create a surface plot and projected filled contour plot under it.\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(X, Y, Z, rstride=3, cstride=3, linewidth=1, antialiased=True,\n",
    "                    cmap=cm.viridis)\n",
    "\n",
    "    cset = ax.contourf(X, Y, Z, zdir='z', offset=-0.15, cmap=cm.viridis)\n",
    "\n",
    "    # Adjust the limits, ticks and view angle\n",
    "    ax.set_zlim(-0.15,0.2)\n",
    "    ax.set_zticks(np.linspace(0,0.2,5))\n",
    "    ax.view_init(27, -21)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Discriminant Analysis(GDA) model\n",
    "GDA is perfect for the case where the problem is a classificaiton problem and input variable is continious and fall into a gaussian distribution. For simplicisity, lets assume we are working on a binary classification problem ( $ \\mathcal{y} \\in \\{0, 1\\} $). We will apply GDA model which will model $ p(x|y) $ using a multivariate normal distribution. The model is:\n",
    "$$\n",
    "y ~ Bernoulli(\\phi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
