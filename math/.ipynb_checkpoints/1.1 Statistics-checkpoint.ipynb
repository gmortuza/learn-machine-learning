{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.1 Statistics </h1>\n",
    "<p> This notebook focus only the statics requried for Machine Learning. Here we will only use numpy<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1.1 Mean, Meadian, Mode </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Mean: </strong> Mean is the average of the sample data. By dividing summation of all sample value by the number of sample value we can get the mean. \n",
    "\\begin{align}\n",
    "\\bar{x} & = \\frac{1}{n}\\sum_{i=1}^n x_i\\\\\n",
    "\\end{align}\n",
    "<strong>Median: </strong> Median is the midpoint of a sorted dataset. If the dataset has too many outlier then median is more useful than mean. For example, to understand what is the per capita income of a country the median is taken because the rich may be extremely rich which would skew the average and show a different picture than what the average people might experience. In that case, probably, taking the median would give a better insight.\n",
    "\n",
    "<strong>Mode: </strong> It's the most common value in the dataset. It's usefull to understand the concept of clustering or number of hit of a specific value. For example, a retailer may want to understand the mode of sizes purchased so that he can set stocking labels optimally. Say, store A has a mode of ‘small’ while store B has a mode of ‘XXL’.\n",
    "\n",
    "For a discrete random variable, the value with highest probability (the location at which the probability mass function has its peak); for a continuous random variable, a location at which the probability density function has a local peak.\n",
    "<p style=\"text-align:center\"><img src=\"mean-median-mode.png\" /> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 36 69 90 29  2 96 88 23 89]\n",
      " [48 96 35 71 40 53 60 43 20 49]\n",
      " [23 67 94 81 27 67 47 61  7 25]\n",
      " [12 94 86 28 72 81 90 65 76 71]\n",
      " [74  3 68 78 85 13 24 64 53  7]]\n",
      "Mean: [[44 59 70 69 50 43 63 64 35 48]]\n",
      "Median: [[48. 67. 69. 78. 40. 53. 60. 64. 23. 49.]] \n",
      "Mode: ModeResult(mode=array([[12,  3, 35, 28, 27,  2, 24, 43,  7,  7]]), count=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))\n"
     ]
    }
   ],
   "source": [
    "# calculating mean median mode.\n",
    "dataset = (np.random.rand(5,10) * 100).astype(int)\n",
    "print(dataset)\n",
    "# Axis 0 will take the mean along y axis, axis 1 will calculate mean along x axis\n",
    "# keepdims will use the same dimension\n",
    "print(f\"Mean: {np.mean(dataset, axis=0, keepdims=True, dtype=int)}\")\n",
    "print(f\"Median: {np.median(dataset, axis=0, keepdims=True)} \")\n",
    "print(f\"Mode: {stats.mode(dataset, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1.2 Normal Distribution </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Data creates a bell curve</li>\n",
    "    <li>The curve is symmetric about the mean</li>\n",
    "    <li>Most of the data is seen near the mean</li>\n",
    "    <li>Notation: $ \\mathcal{N}(\\mu,\\,\\sigma^{2})\\ $ </li>\n",
    "    <li>Mean = Median = Mode = $ \\mu $</li>\n",
    "    <li> variance = $ \\sigma^{2} $. Standard Devation = $ \\sigma $ </li>\n",
    "    <li>PDF:  </li>\n",
    "</ul>\n",
    "\\begin{align}\n",
    "P(x) = \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2}\n",
    "\\end{align}\n",
    "<img src=\"normal-distribution.png\" style=\"max-width:50%\"/>\n",
    "<strong>PDF(Probability Density Function):</strong> \n",
    "<ul>\n",
    "    <li>A random variable is continuous if it can be described by a PDF</li>\n",
    "    <li>The probability of happening a <strong>super exact</strong> random variable over any distribution is zero. Cause the probability is the area under the curve. And for a exact variable the we will not get a area instead we will get a line. And the area of the line is zero. If we say the probability of getting an exact random variable $ \\mu $ is zero. But the probability of getting a random variable between $ \\mu - \\sigma $ and $ \\mu + \\sigma $ is 68.27%</li>\n",
    "</ul>\n",
    "\\begin{align}\n",
    "\\int_{\\mu - \\sigma}^{\\mu + \\sigma} \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2} dx = 68.27\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\int_{\\mu - 2\\sigma}^{\\mu + 2\\sigma} \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2} dx = 95.45\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\int_{\\mu - 3\\sigma}^{\\mu + 3\\sigma} \\frac{1}{\\sigma \\sqrt {2\\pi } }e^-\\frac{(x - \\mu)^2}{2 \\sigma ^2} dx = 99.73\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.3 Other distributions: </h3>\n",
    "<strong>Bernoulli distribution:</strong> A random variable distributed according to the Bernoulli distribution can take on two possible values {0, 1}. Let, the probability of a random variable X = 1 is p. So, $ P(X = 1) = p $. \n",
    "\\begin{equation}\n",
    "  P(X)=\\begin{cases}\n",
    "    1 - p, & \\text{if $X=0$}.\\\\\n",
    "    p, & \\text{if $X=1$}.\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "More compactly, $ P(X) = p^x(1-p)^{1-x} $. And this is the PMF(Probability Mass Function) for Bernoulli distribution. One of the example of bernoulli's distribution is Logistic regression.\n",
    "\n",
    "<strong>Binomial distribution</strong> A sequence of identical bernoulli's event. If X is a Binomial random variable, we denote this $ X ∼ Bin(n, p) $, where p is the probability of success in a given trial and n is total number of trial. Probabililty Mass Function is given by: \n",
    "\\begin{equation}\n",
    "    P(X=k) = \\binom nk p^k(1-p)^{n-k}\n",
    "\\end{equation}\n",
    "Mean = $ np $. And variance = $ np(1-p) $\n",
    "\n",
    "<strong>Poisson distribution:</strong> It deals with arrival of events. It measures probability of the number of events happening over a fixed period of time, given a fixed average rate of occurrence and the event take places independently of the time since the last event. It is parameterized by average arrival rate $ \\lambda $. The PMF (Probability Mass Function) is given by:\n",
    "\\begin{equation}\n",
    "P(X = k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}\n",
    "\\end{equation}\n",
    "The mean and the variance is $ \\lambda $\n",
    "Example: You see 100 car goes over a road in a day. What is the probability that next day you will see 120 car running on the road. This can be calculated by poission distribuiton. Here $ \\lambda = 100  \\text{ and }  k = 120 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1.1.4 Standard Deviation </h3>\n",
    "A measure of the amount of variation or dispersion of a set of values. It is a measure of how spread out numbers are. It's value is the square root of the Variance\n",
    "\\begin{equation}\n",
    "\\sigma = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.39106965, 33.53445989, 17.5088549 , 33.74374016, 24.17767565,\n",
       "        35.3327044 , 23.95495773, 23.92153841, 22.64862027, 31.12169661]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use numpy to find standard deviation\n",
    "np.std(dataset, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.5 Correlation</h3>\n",
    "It measures the strength and direction of the linear relationship between two variables. It's a function of covariance. <strong>What sets them apart is the fact that correlation values are standardized whereas, covariance values are not</strong>. We can obtain the correlation coefficient of two variables by dividing the covariance of these variables by the product of the standard deviations of the same values. When we divide the covariance values by the standard deviation, it essentially scales the value down to a limited range of -1 to +1. This is precisely the range of the correlation values.\n",
    "\\begin{equation}\n",
    "\\rho (x, y) = \\frac{Cov(x, y)}{\\sigma_x \\sigma_y} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1.6 Covariance</h3>\n",
    "Variance measures the variation of a single random variable. Covariance is a measure of how much two random variables vary together.\n",
    "\\begin{equation}\n",
    "Var(X) = \\sigma_x^2 = \\frac{1}{n-1}\\sum_{i=1}^n(x_i - \\bar{x})^2 \\\\\n",
    "Cov(X,Y) = \\sigma(x,y) = \\frac{1}{n-1}\\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) \\\\\n",
    "\\sigma(x,x) = \\sigma_x^2\n",
    "\\end{equation}\n",
    "Covariance matrix are symmatric. The diagonal element of the covariance matrix are variant and other elements are covaraince. If the non diagonal element of the covarance matrix are empty then it means the two random variable are independent. It has the units from the product of the units of the two variables. <strong>Use the covariance matrix when the variable are on similar scales and the correlation matrix when the scales of the variables differ.</strong>Using covariance, we can only gauge the direction of the relationship (whether the variables tend to move in tandem or show an inverse relationship). However, it does not indicate the strength of the relationship, nor the dependency between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 36 69 90 29  2 96 88 23 89]\n",
      " [48 96 35 71 40 53 60 43 20 49]\n",
      " [23 67 94 81 27 67 47 61  7 25]\n",
      " [12 94 86 28 72 81 90 65 76 71]\n",
      " [74  3 68 78 85 13 24 64 53  7]]\n",
      "[[1128.72222222   87.61111111  180.94444444 -246.27777778  146.05555556]\n",
      " [  87.61111111  435.83333333  257.5          22.5        -301.27777778]\n",
      " [ 180.94444444  257.5         815.21111111  124.05555556   -5.12222222]\n",
      " [-246.27777778   22.5         124.05555556  720.5        -493.05555556]\n",
      " [ 146.05555556 -301.27777778   -5.12222222 -493.05555556 1013.43333333]]\n"
     ]
    }
   ],
   "source": [
    "# Find covariance using numpy\n",
    "cov = np.cov(dataset)\n",
    "print(dataset)\n",
    "print(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used resources:\n",
    "    <ul>\n",
    "        <li>https://medium.com/technology-nineleaps/basics-of-statistics-for-machine-learning-engineers-bf2887ac716c</li>\n",
    "    <li>https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22</li>\n",
    "    <li>https://datascienceplus.com/understanding-the-covariance-matrix/</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
